{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":18613,"sourceType":"datasetVersion","datasetId":5839}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n\nimage_paths = []\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        path = os.path.join(dirname, filename)\n        if path.endswith('png'):\n            image_paths.append(path)\n    \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-28T09:00:27.171360Z","iopub.execute_input":"2024-03-28T09:00:27.171648Z","iopub.status.idle":"2024-03-28T09:02:32.432313Z","shell.execute_reply.started":"2024-03-28T09:00:27.171622Z","shell.execute_reply":"2024-03-28T09:02:32.431496Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/data/test_list.txt') as t:\n    test_paths = list(map(lambda z: z.strip(), t.readlines()))\n    \nwith open('/kaggle/input/data/train_val_list.txt') as t:\n    train_paths = list(map(lambda z: z.strip(), t.readlines()))\n    \nentries = pd.read_csv('/kaggle/input/data/Data_Entry_2017.csv', index_col='Image Index')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:32.433944Z","iopub.execute_input":"2024-03-28T09:02:32.434355Z","iopub.status.idle":"2024-03-28T09:02:32.821085Z","shell.execute_reply.started":"2024-03-28T09:02:32.434329Z","shell.execute_reply":"2024-03-28T09:02:32.820254Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"from PIL import Image\nfrom sklearn.preprocessing import LabelEncoder\n\nimport tqdm","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:32.822307Z","iopub.execute_input":"2024-03-28T09:02:32.822744Z","iopub.status.idle":"2024-03-28T09:02:33.854590Z","shell.execute_reply.started":"2024-03-28T09:02:32.822711Z","shell.execute_reply":"2024-03-28T09:02:33.853836Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"le = LabelEncoder()\nentries['labels'] = le.fit_transform(entries['Finding Labels'])","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:33.855639Z","iopub.execute_input":"2024-03-28T09:02:33.856053Z","iopub.status.idle":"2024-03-28T09:02:33.906080Z","shell.execute_reply.started":"2024-03-28T09:02:33.856028Z","shell.execute_reply":"2024-03-28T09:02:33.905260Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"j = []\nfor i in pd.unique(entries['Finding Labels']):\n    j.extend(i.split('|'))\nunique = np.unique(np.array(j)).tolist()\n\nlabels = dict(zip(unique, range(len(unique))))","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:33.908250Z","iopub.execute_input":"2024-03-28T09:02:33.908533Z","iopub.status.idle":"2024-03-28T09:02:33.927263Z","shell.execute_reply.started":"2024-03-28T09:02:33.908508Z","shell.execute_reply":"2024-03-28T09:02:33.926329Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"from torchvision import transforms\nimport torch\ntrns = transforms.Compose(\n    [\n        transforms.Resize((280, 280)),\n        transforms.ToTensor(),\n        lambda t: torch.zeros(3, 280, 280) + t[0:1, :, :],\n        lambda t: torch.vstack(\n            (t[[1, 2], :, :] * -1 + t[[1, 2], :, :], t[0:1, :, :])\n        )\n    ]\n)\n\n\n\n\ndef get_data(paths, l, u):\n    X_data = []\n    data_y = []\n    for path in tqdm.tqdm(paths[l: u]):\n        for image_path in image_paths:\n            if image_path.endswith(path):\n                y = torch.zeros(15)\n                p = Image.open(image_path)\n                t_x = trns(p)\n                X_data.append(t_x)\n                diseases = entries.loc[path]['Finding Labels'].split('|')\n                for d in diseases:\n                    y[labels[d]] = 1\n                data_y.append(y)\n                break\n    return torch.stack(X_data), torch.stack(data_y)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:33.928353Z","iopub.execute_input":"2024-03-28T09:02:33.928622Z","iopub.status.idle":"2024-03-28T09:02:40.463978Z","shell.execute_reply.started":"2024-03-28T09:02:33.928599Z","shell.execute_reply":"2024-03-28T09:02:40.463179Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":"# Model","metadata":{}},{"cell_type":"code","source":"dinov2_vits14 = torch.hub.load('facebookresearch/dinov2', 'dinov2_vits14')","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:40.465105Z","iopub.execute_input":"2024-03-28T09:02:40.465518Z","iopub.status.idle":"2024-03-28T09:02:45.226117Z","shell.execute_reply.started":"2024-03-28T09:02:40.465491Z","shell.execute_reply":"2024-03-28T09:02:45.225264Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stderr","text":"Downloading: \"https://github.com/facebookresearch/dinov2/zipball/main\" to /root/.cache/torch/hub/main.zip\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/swiglu_ffn.py:51: UserWarning: xFormers is not available (SwiGLU)\n  warnings.warn(\"xFormers is not available (SwiGLU)\")\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/attention.py:33: UserWarning: xFormers is not available (Attention)\n  warnings.warn(\"xFormers is not available (Attention)\")\n/root/.cache/torch/hub/facebookresearch_dinov2_main/dinov2/layers/block.py:40: UserWarning: xFormers is not available (Block)\n  warnings.warn(\"xFormers is not available (Block)\")\nDownloading: \"https://dl.fbaipublicfiles.com/dinov2/dinov2_vits14/dinov2_vits14_pretrain.pth\" to /root/.cache/torch/hub/checkpoints/dinov2_vits14_pretrain.pth\n100%|██████████| 84.2M/84.2M [00:01<00:00, 62.0MB/s]\n","output_type":"stream"}]},{"cell_type":"code","source":"class CLF(torch.nn.Module):\n    def __init__(self, encoder, num_classes=15, dim=384):\n        super(CLF, self).__init__()\n        self.encoder = encoder\n        self.dim = dim\n        self.num_classes = num_classes\n        self.head = torch.nn.Linear(self.dim, self.num_classes)\n#         self.local = torch.nn.Linear(self.dim, 4)\n        \n    def forward(self, x):\n        x = self.encoder(x)\n        return self.head(x)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:45.227240Z","iopub.execute_input":"2024-03-28T09:02:45.229088Z","iopub.status.idle":"2024-03-28T09:02:45.235222Z","shell.execute_reply.started":"2024-03-28T09:02:45.229059Z","shell.execute_reply":"2024-03-28T09:02:45.234284Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"def train(model, x, y, loss_fn, optimizer):\n    model.train()\n    \n    optimizer.zero_grad()\n    \n    y_hat = model(x)\n    \n    loss = loss_fn(y_hat, y)\n    \n    loss.backward()\n    \n    optimizer.step()\n    \n    return loss.item()","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:45.236564Z","iopub.execute_input":"2024-03-28T09:02:45.237037Z","iopub.status.idle":"2024-03-28T09:02:45.252076Z","shell.execute_reply.started":"2024-03-28T09:02:45.237007Z","shell.execute_reply":"2024-03-28T09:02:45.251143Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"@torch.no_grad()\ndef eval(model, x, y):\n    model.eval()\n    \n    y_hat = model(x)\n    \n    return ((y_hat > 0) == y).float().mean(0)","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:02:45.253066Z","iopub.execute_input":"2024-03-28T09:02:45.253353Z","iopub.status.idle":"2024-03-28T09:02:45.262523Z","shell.execute_reply.started":"2024-03-28T09:02:45.253328Z","shell.execute_reply":"2024-03-28T09:02:45.261776Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nclf = CLF(dinov2_vits14).to(device)\nopt = torch.optim.Adam(clf.parameters(), lr=1e-3)\nloss_fn = torch.nn.BCEWithLogitsLoss()\n# print(eval(clf, x, y))\nbatch_size = 16\n\nfor i in range(1000):\n    e_loss = 0\n    accs = []\n    for i in range(len(train_paths)):\n        j = i + 2500\n        if j > len(train_paths):\n            j = len(train_paths)\n        print('Getting data')\n        X_train, train_y = get_data(train_paths, i, j)\n        print('Training')\n        for x, y in tqdm.tqdm(zip(\n            torch.split(X_train, split_size_or_sections=batch_size),\n            torch.split(train_y, split_size_or_sections=batch_size)\n        )):\n    #     x = (torch.stack(_)[:5])\n    #     y = torch.tensor(train_y[:5])\n            e_loss += train(clf, x.to(device), y.to(device), loss_fn, opt)\n    for i in range(len(test_paths)):\n        j = i + 2500\n        if j > len(test_paths):\n            j = len(test_paths)\n        print('Getting data')\n        X_test, test_y = get_data(test_paths, i, j)\n        print('Testing')\n        for x, y in tqdm.tqdm(zip(\n            torch.split(X_test, split_size_or_sections=batch_size),\n            torch.split(test_y, split_size_or_sections=batch_size)\n        )):\n            \n            acc = eval(clf, x.to(device), y.to(device))\n            accs.append(acc)\n    print('Epoch', i)\n    print('Loss: ', e_loss)\n    print(torch.stack(accs).mean(0))\n#     break\n    \n    print('------------')\n# dinov2_vits14","metadata":{"execution":{"iopub.status.busy":"2024-03-28T09:05:41.345590Z","iopub.execute_input":"2024-03-28T09:05:41.346304Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:25<00:00, 29.41it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.69it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:23<00:00, 29.80it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:24<00:00, 29.60it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:24<00:00, 29.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:23<00:00, 29.78it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:23<00:00, 29.81it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:24<00:00, 29.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:24<00:00, 29.67it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"157it [00:33,  4.68it/s]\n","output_type":"stream"},{"name":"stdout","text":"Getting data\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 2500/2500 [01:23<00:00, 29.93it/s]\n","output_type":"stream"},{"name":"stdout","text":"Training\n","output_type":"stream"},{"name":"stderr","text":"111it [00:23,  4.69it/s]","output_type":"stream"}]}]}